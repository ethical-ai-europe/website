---
title: "AI Compliance Checklist"
description: "Practical checklist for EU AI Act compliance—inventory, classify, document, govern"
date: "2025-12-25"
language: "en"
---

# AI Compliance Checklist

**Use this checklist to track your organization's AI compliance status.** Whether you're just getting started or conducting a periodic review, this practical tool will help you identify gaps and prioritize actions.

This checklist is most relevant for organizations using high-risk AI or those wanting to ensure responsible AI use at any level. For minimal-risk AI (most common AI tools), use this as a best-practice guide rather than a strict requirement.

---

## 1. AI Inventory

*Do you know what AI you're using?*

### Complete an AI Inventory

- [ ] **Listed all AI systems in use** across the organization
- [ ] **Identified the purpose** of each AI system
- [ ] **Documented data inputs** (what data does it process?)
- [ ] **Documented outputs** (what decisions or recommendations does it produce?)
- [ ] **Identified vendors/providers** for each AI system
- [ ] **Recorded deployment dates** (when did you start using each system?)
- [ ] **Assigned responsibility** (who manages each AI system?)

### Inventory Template

| System Name | Purpose | Data Inputs | Outputs | Vendor | Deployed | Owner | Risk Level |
|-------------|---------|-------------|---------|--------|----------|-------|------------|
| *Example* | *HR screening* | *CVs, applications* | *Candidate rankings* | *HireTech* | *Jan 2024* | *HR Mgr* | *High* |

**Why this matters:** You can't manage AI you don't know about. Incomplete inventories are a common compliance gap.

[More guidance on AI inventory →](/en/for-organizations/sme-guide)

---

## 2. Risk Classification

*Do you know your risk levels?*

### Classify Each AI System

- [ ] **Assessed each system's risk level** according to EU AI Act categories
- [ ] **Identified any prohibited uses** (social scoring, certain biometrics, manipulation)
- [ ] **Flagged high-risk systems** requiring full compliance
- [ ] **Identified limited-risk systems** requiring transparency
- [ ] **Documented classification rationale** for each system

### Risk Categories Reference

| Risk Level | Description | Examples | Key Obligations |
|------------|-------------|----------|-----------------|
| **Prohibited** | Banned entirely | Social scoring, certain biometric ID, manipulation | Do not use |
| **High Risk** | Significant impact on rights/safety | Employment AI, credit scoring, education, law enforcement | Full compliance requirements |
| **Limited Risk** | Transparency obligations | Chatbots, emotion recognition, deepfakes | Disclosure to users |
| **Minimal Risk** | No specific obligations | Spam filters, recommendations, games | Best practices |

### High-Risk Sector Checklist

Is your AI used in any of these areas?

- [ ] **Biometric identification** (remote or otherwise)
- [ ] **Critical infrastructure** (transport, water, energy, digital)
- [ ] **Education and training** (access, assessment, evaluation)
- [ ] **Employment** (recruiting, hiring, performance, termination)
- [ ] **Essential services** (credit, benefits, emergency services)
- [ ] **Law enforcement** (risk assessment, polygraphs, evidence evaluation)
- [ ] **Migration and asylum** (border control, visa processing)
- [ ] **Justice and democracy** (legal research, court decisions)

**If yes to any:** Classify as high-risk and proceed to Section 3.

[More on risk classification →](/en/for-organizations)

---

## 3. High-Risk AI Compliance

*For systems classified as high-risk*

### Risk Management System

- [ ] **Established a risk management system** (documented, updated throughout lifecycle)
- [ ] **Identified and analyzed known/foreseeable risks**
- [ ] **Estimated risks based on data and design**
- [ ] **Evaluated risks from intended use and misuse**
- [ ] **Adopted risk management measures**
- [ ] **Tested system for risk mitigation effectiveness**
- [ ] **Documented residual risk** (what risk remains?)
- [ ] **Communicated residual risk to deployers/users**

### Data Governance

- [ ] **Documented data collection methods**
- [ ] **Ensured training data is relevant and representative**
- [ ] **Examined data for biases** and documented findings
- [ ] **Identified and addressed data gaps**
- [ ] **Established data quality metrics**
- [ ] **Documented data retention and deletion policies**
- [ ] **Ensured GDPR compliance** for personal data

### Technical Documentation

- [ ] **Created comprehensive technical documentation** including:
  - [ ] General system description and purpose
  - [ ] System architecture and design
  - [ ] Development process description
  - [ ] Training, validation, and testing details
  - [ ] Performance metrics and testing results
  - [ ] Risk management documentation
  - [ ] Lifecycle management processes
  - [ ] Compliance standards applied

### Human Oversight

- [ ] **Designed system for effective human oversight**
- [ ] **Defined human oversight procedures**
- [ ] **Identified who is responsible for oversight**
- [ ] **Provided tools for operators to understand AI outputs**
- [ ] **Enabled operators to override or reverse AI decisions**
- [ ] **Trained operators on system capabilities and limitations**
- [ ] **Created escalation procedures** for problematic outputs
- [ ] **Documented override procedures and tracked usage**

### Accuracy, Robustness, and Security

- [ ] **Tested for accuracy** appropriate to intended purpose
- [ ] **Tested for robustness** against errors and inconsistencies
- [ ] **Conducted cybersecurity testing**
- [ ] **Documented known limitations**
- [ ] **Established ongoing monitoring procedures**
- [ ] **Created incident response procedures**

### Registration (EU Database)

- [ ] **Determined if registration is required**
  - High-risk AI systems generally require registration
  - Public sector deployers have registration obligations
- [ ] **Prepared registration information**
- [ ] **Registered system in EU database** (when database is operational)
- [ ] **Established process for updating registration** as system changes

[More on high-risk requirements →](/en/guidelines)

---

## 4. Transparency

*Are you being open about AI use?*

### User Notification

- [ ] **Users informed when interacting with AI** (especially chatbots)
- [ ] **AI-generated content is labeled** where required
- [ ] **Emotion recognition disclosures made** where applicable
- [ ] **Deepfake/synthetic content clearly marked**

### Explainability

- [ ] **Affected persons can request explanations** of AI decisions
- [ ] **Explanations are provided in accessible language**
- [ ] **Decision factors are documented and explainable**
- [ ] **Staff trained to explain AI outputs**

### Documentation Accessibility

- [ ] **System descriptions available** in plain language
- [ ] **User instructions provided and accessible**
- [ ] **Privacy policies updated** to reflect AI use
- [ ] **Website/customer communications updated** as needed

### Public Sector Additional Requirements

- [ ] **Public register entries completed** (for public authorities)
- [ ] **Citizen-facing materials explain AI use**
- [ ] **Appeals and redress processes documented and communicated**

[More on transparency obligations →](/en/rights)

---

## 5. Governance

*Who's responsible, and are they prepared?*

### Accountability

- [ ] **Responsible person or team identified** for AI governance
- [ ] **Roles and responsibilities documented**
- [ ] **Reporting lines established** for AI issues
- [ ] **Board/leadership oversight defined** where appropriate

### Training

- [ ] **Staff using AI systems are trained** on proper use
- [ ] **Training covers system limitations and risks**
- [ ] **Training covers when to override or escalate**
- [ ] **Training records maintained**
- [ ] **Refresher training scheduled** as needed

### Incident Response

- [ ] **Incident reporting process defined**
- [ ] **Staff know how to report AI problems**
- [ ] **Response procedures documented**
- [ ] **Serious incident reporting procedures** comply with AI Act requirements
- [ ] **Communication templates prepared** for stakeholder notification

### Regular Review

- [ ] **Periodic review scheduled** (at least annually)
- [ ] **Review process documented**
- [ ] **Previous issues tracked and followed up**
- [ ] **Compliance status reported to leadership**

### Vendor Management

- [ ] **Vendor AI Act compliance verified**
- [ ] **Contract terms reviewed** for AI compliance requirements
- [ ] **Vendor documentation obtained and filed**
- [ ] **Vendor performance monitored**
- [ ] **Exit strategy exists** for each AI vendor

[More on governance →](/en/guidelines)

---

## Timeline Reference

### What's Required When?

| Date | Requirement | Applies To |
|------|-------------|------------|
| **February 2025** | Prohibited practices banned | All AI users |
| **August 2025** | General-purpose AI rules apply | GPAI providers |
| **August 2026** | High-risk AI requirements apply | High-risk AI systems |
| **August 2027** | All provisions in force | All AI systems |

### Priority Actions by Timeline

**Now → February 2025**
- Complete AI inventory
- Identify any prohibited uses (stop immediately)
- Begin risk classification

**February 2025 → August 2025**
- Confirm no prohibited practices in use
- Complete risk classification
- Begin high-risk compliance for critical systems

**August 2025 → August 2026**
- Complete high-risk compliance preparation
- Establish governance structures
- Implement training programs
- Prepare registration for high-risk systems

**August 2026 onwards**
- Full compliance required for high-risk AI
- Ongoing monitoring and review
- Annual compliance audits

---

## Quick Reference: Who Needs What?

| Organization Type | Likely Requirements |
|-------------------|---------------------|
| **SME using common AI tools** | Minimal—basic awareness, no prohibited uses |
| **SME with customer-facing AI** | Limited—transparency disclosures |
| **Organization using HR/credit AI** | High-risk—full compliance |
| **Educational institution** | High-risk—full compliance for access/assessment AI |
| **Public sector body** | High-risk—enhanced transparency, registration, redress |
| **AI developer** | Extensive—provider obligations, conformity assessment |

---

## Tracking Your Progress

### Compliance Status Summary

| Section | Status | Last Reviewed | Next Review |
|---------|--------|---------------|-------------|
| 1. AI Inventory | ☐ Not started ☐ In progress ☐ Complete | | |
| 2. Risk Classification | ☐ Not started ☐ In progress ☐ Complete | | |
| 3. High-Risk Compliance | ☐ N/A ☐ Not started ☐ In progress ☐ Complete | | |
| 4. Transparency | ☐ Not started ☐ In progress ☐ Complete | | |
| 5. Governance | ☐ Not started ☐ In progress ☐ Complete | | |

---

## Resources and Help

### Official Resources
- **[EU AI Act Text](https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:32024R1689)** - Official legal text
- **[European Commission AI Page](https://digital-strategy.ec.europa.eu/en/policies/european-approach-artificial-intelligence)** - Official EU guidance
- **National AI authorities** - Check your country's implementation body

### This Site
- [For Organizations (Overview) →](/en/for-organizations)
- [SME Guide →](/en/for-organizations/sme-guide)
- [Educators Guide →](/en/for-organizations/educators)
- [Public Sector Guide →](/en/for-organizations/public-sector)
- [AI Development Guidelines →](/en/guidelines)
- [AI Ethics Principles →](/en/principles)

### When to Get Help
Consider professional assistance if:
- You have high-risk AI systems
- You're unsure about classification
- You operate in multiple jurisdictions
- You've identified potential prohibited uses
- You're developing AI products

---

*This checklist is for guidance only. For specific legal requirements in your situation, consult qualified legal or compliance professionals.*
