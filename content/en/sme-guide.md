---
title: "AI Guide for Small & Medium Businesses"
description: "Practical AI guidance for SME owners and managers‚Äîno legal team required"
date: "2025-12-25"
language: "en"
---

# AI Guide for Small & Medium Businesses

**AI can help your business compete, innovate, and serve customers better.** But like any powerful tool, it comes with responsibilities. This guide helps SME owners and managers understand what the EU AI Act means for your business‚Äîin plain language, with practical steps.

You don't need a legal team or a dedicated compliance department. You need to understand what you're using and take reasonable steps to use it responsibly.

---

## Am I Affected? A Quick Assessment

Your obligations depend on *how* you're using AI. Here's a quick guide:

### üü¢ Using AI Tools for Internal Tasks
*Examples: ChatGPT for drafting emails, AI assistants for research, automated scheduling*

**Your obligations:** Minimal
- Be aware you're using AI
- Don't share sensitive data inappropriately
- Follow the tool provider's terms of service
- Consider informing employees about AI tool usage

### üü° Deploying AI in Customer-Facing Systems
*Examples: AI chatbot on your website, automated product recommendations, AI-powered customer service*

**Your obligations:** Moderate
- Disclose to customers when they're interacting with AI
- Ensure AI-generated content is accurate
- Have a process for handling complaints
- Document what systems you're using

### üü† Using AI for Significant Decisions
*Examples: AI-assisted hiring screening, credit decisions, employee performance evaluation*

**Your obligations:** Significant‚Äîlikely "high-risk"
- Full compliance requirements apply
- Risk assessment required
- Human oversight mandatory
- Detailed documentation needed
- [See Compliance Checklist ‚Üí](/en/for-organizations/compliance-checklist)

### üî¥ Building AI Products or Features
*Examples: Developing AI into your product, training custom models, creating AI-powered services*

**Your obligations:** Extensive
- May need conformity assessments
- Technical documentation requirements
- Ongoing monitoring obligations
- Consider consulting an expert

---

## Understanding Risk Categories

The EU AI Act uses a risk-based approach. Understanding where your AI use falls helps you know what's required.

### Minimal Risk ‚úÖ
Most AI applications fall here. Think:
- Spam filters
- AI-powered search
- Recommendation engines
- General productivity tools

**What's required:** Basic best practices. No specific compliance obligations, but responsible use is always good business.

### Limited Risk ‚ö†Ô∏è
AI systems requiring transparency, including:
- Chatbots (users must know they're not talking to a human)
- Emotion recognition systems
- AI-generated content (deepfakes, synthetic media)

**What's required:** Disclosure. Users must be told when they're interacting with AI or viewing AI-generated content.

### High Risk üî∂
AI in sensitive areas with significant impact on people:
- **Employment:** AI in recruiting, hiring, performance evaluation
- **Credit:** AI for creditworthiness or loan decisions
- **Essential services:** Access to benefits, utilities, services
- **Education:** Determining access or outcomes (less relevant for most SMEs)

**What's required:** Full compliance‚Äîrisk management, documentation, human oversight, testing, registration. [See the full checklist ‚Üí](/en/for-organizations/compliance-checklist)

### Prohibited ‚ùå
Certain AI uses are banned entirely:
- Manipulative AI designed to distort behavior
- Exploiting vulnerabilities (age, disability)
- Social scoring systems
- Real-time biometric identification in public (with narrow exceptions)

**What's required:** Don't do it. If a vendor offers you something that sounds like this, walk away.

---

## 5 Practical Steps for SMEs

### 1. Inventory Your AI Use üìã

You can't manage what you don't know about. Create a simple list:

| AI System/Tool | Purpose | Data Involved | Vendor | Risk Level |
|----------------|---------|---------------|--------|------------|
| *Example: ChatGPT* | *Email drafting* | *No personal data* | *OpenAI* | *Minimal* |
| *Example: HireBot Pro* | *Resume screening* | *Applicant data* | *HireBot Inc* | *High* |

Start simple. You can add detail later.

### 2. Classify Risk Levels üéØ

For each system, ask:
- Does this AI make or influence significant decisions about people?
- Could someone be meaningfully harmed by a wrong output?
- Does it involve sensitive personal data?
- Is it in a regulated sector (employment, credit, essential services)?

If you answer "yes" to any of these, you likely need more than minimal compliance.

### 3. Document What You're Using and Why üìù

Good documentation doesn't have to be complicated. For each AI system, record:
- What it does
- What data it processes
- Who the vendor is
- Why you chose it
- When you started using it
- Who's responsible for it

This protects you and helps you respond to any questions.

### 4. Ensure Human Oversight üë§

For any AI that affects people meaningfully:
- A human should review important decisions
- Staff should be trained to understand the AI's limitations
- There should be a process to override or escalate AI outputs
- Someone should be responsible for monitoring performance

### 5. Be Transparent üîç

Good transparency is simple:
- Tell customers when they're interacting with AI (chatbots, automated responses)
- Explain when AI plays a role in decisions that affect them
- Be honest about what AI can and can't do
- Respond to questions about your AI use

---

## Common Scenarios: What Do I Do?

### "We use ChatGPT for customer emails"

**Risk level:** Minimal to Limited

**What to do:**
- Consider disclosing if emails are AI-assisted (not legally required but builds trust)
- Review AI outputs before sending‚Äîespecially for complex matters
- Don't input confidential customer data into the tool
- Have guidelines for staff on appropriate use

### "We bought an AI hiring tool"

**Risk level:** HIGH

**What to do:**
- This is high-risk AI under the EU AI Act
- Get documentation from the vendor about compliance, bias testing, accuracy
- Ensure human review of all hiring decisions
- Never let the AI make final decisions alone
- Document your use and decision-making process
- Consider whether you actually need this tool
- [Review full requirements ‚Üí](/en/for-organizations/compliance-checklist)

### "We want to add a chatbot to our website"

**Risk level:** Limited

**What to do:**
- Clearly disclose to users they're talking to a bot
- Provide an easy way to reach a human
- Monitor conversations for issues
- Train the bot on accurate information
- Have a plan for when the bot gives wrong answers

### "We're building an AI feature into our product"

**Risk level:** Varies‚Äîpotentially significant

**What to do:**
- Assess the risk level based on use case and impact
- If high-risk, full compliance requirements apply
- Consider conformity assessment requirements
- Document your development process
- Build in monitoring and feedback mechanisms
- You may want to consult with an AI compliance expert

---

## Resources: Where to Get Help

### Official Sources
- **[EU AI Act Portal](https://digital-strategy.ec.europa.eu/en/policies/european-approach-artificial-intelligence)** - Official information from the European Commission
- **Your national AI authority** - Check your country's implementation body for local guidance
- **Chamber of Commerce** - Many are developing SME-focused AI guidance

### Questions to Ask Your Vendors
If you're using AI from third parties, ask:
1. How is this AI classified under the EU AI Act?
2. What documentation can you provide about testing and accuracy?
3. How do you test for and mitigate bias?
4. What data does the system collect and process?
5. What happens if the AI makes a mistake?
6. Can we audit or review how the system works?

### When to Get Professional Help
Consider consulting an expert if:
- You're deploying high-risk AI
- You're building AI into your products
- You're in a regulated industry
- You've received a complaint about your AI
- You're unsure about your obligations

---

## Timeline: What's Required When?

The EU AI Act is phased in gradually:

| Date | What Happens |
|------|--------------|
| **February 2025** | Prohibited AI practices banned |
| **August 2025** | General-purpose AI rules apply |
| **August 2026** | High-risk AI requirements apply |
| **August 2027** | All provisions in force |

**Our advice:** Don't wait. Start with your AI inventory now. The organizations that prepare early will have the smoothest transitions.

---

## Key Takeaways

‚úÖ **Most SMEs using common AI tools have minimal obligations**‚Äîdon't overcomplicate it

‚úÖ **Know what you're using**‚Äîan AI inventory is your foundation

‚úÖ **Be honest about risk levels**‚Äîespecially for HR and decision-making AI

‚úÖ **Keep humans in the loop**‚Äîespecially for important decisions

‚úÖ **Be transparent**‚Äîdisclosure builds trust

‚úÖ **Document as you go**‚Äîit's easier than catching up later

‚úÖ **Start now**‚Äîearly preparation beats last-minute scrambles

---

*Need the detailed checklist? [Go to the Compliance Checklist ‚Üí](/en/for-organizations/compliance-checklist)*

*Questions about your specific situation? Consider consulting your national AI authority or a qualified professional.*
