---
title: "For Journalists & Activists"
description: "Hold AI to account"
date: "2025-12-25"
language: "en"
---

# Hold AI to Account

**AI is transforming society, and the public deserves to understand how.** As a journalist or activist, you play a crucial role in investigating AI systems, telling human stories, and ensuring accountability.

This guide helps you navigate the AI landscape in Europe‚Äîunderstand the regulatory framework, find story angles, access reliable sources, and connect with experts.

---

## What You Need

### Understand the Regulatory Landscape
The EU AI Act is the world's first comprehensive AI law. Knowing its structure helps you identify where systems might fall short.

### Find Stories and Angles
AI touches every sector‚Äîwork, education, healthcare, public services. Real people are affected by these systems every day.

### Access Reliable Sources
Cut through the hype. We've curated authoritative sources and expert organizations.

### Connect with Experts
When you need commentary, analysis, or background, knowing who to contact makes the difference.

---

## Your Curated Guide

### üåç Understanding the Landscape

#### EU AI Act Overview
The essentials of Europe's AI regulation‚Äîwhat it covers, how it works, and why it matters globally.

[About the EU AI Act ‚Üí](/en/about)

#### The Issues
Deep dives into the key challenges: bias and discrimination, privacy and surveillance, transparency, automation and employment, and democratic oversight.

[Understand the Issues ‚Üí](/en/issues)

---

### üì∞ Story Angles

AI stories are everywhere. Here are some angles worth investigating:

#### Workplace Surveillance
Workers are being monitored by AI in unprecedented ways. From productivity scoring to emotion detection, there are stories of workers pushing back‚Äîand of practices that cross legal lines.

[Workplace Surveillance Rights ‚Üí](/en/rights/workplace-surveillance)

#### AI in Public Services
When government uses AI to allocate benefits, detect fraud, or make decisions about citizens, the stakes are highest. Mistakes can devastate lives, and public trust is at risk.

[AI in Public Services ‚Üí](/en/daily-life/public-services)

#### Hiring Discrimination
AI hiring tools promise efficiency but can perpetuate bias. Candidates are being screened by algorithms they never see. What recourse do they have?

[AI in Hiring ‚Üí](/en/daily-life/hiring)

#### Facial Recognition Deployment
Where is facial recognition being used? Who authorizes it? What safeguards exist? The EU has new restrictions‚Äîare they being followed?

[Facial Recognition Rules ‚Üí](/en/rights/facial-recognition)

#### Education AI
Schools are adopting AI for everything from personalized learning to proctoring. Parents and students often don't know what's being used or what data is collected.

[AI in Education ‚Üí](/en/daily-life/education)

---

### ‚öñÔ∏è Rights Framework

Understanding what rights people have helps you identify when those rights are being violated.

#### What Rights Do People Have?
A plain-language guide to AI rights under European law‚Äîthe right to know, the right to explanation, the right to human review, and the right to object.

[Your AI Rights ‚Üí](/en/rights)

#### What Can People Do?
Practical guidance on how individuals can exercise their rights‚Äîfrom template letters to complaint processes.

[Take Action ‚Üí](/en/take-action)

---

### üìö Resources for Journalists

#### Key EU Documents and Sources
Official EU legislation, guidance documents, and authoritative sources for your reporting.

[AI Ethics Resources ‚Üí](/en/resources)

#### Organizations to Contact
Research institutions, civil society organizations, and expert groups working on AI accountability.

*Key organizations include:*
- AI Now Institute
- Algorithm Watch
- Access Now
- European Digital Rights (EDRi)
- Partnership on AI
- The Ada Lovelace Institute

#### Enforcement Timeline
The EU AI Act is being phased in:

| Date | What Happens |
|------|--------------|
| **February 2025** | Prohibited AI practices banned |
| **August 2025** | General-purpose AI rules apply |
| **August 2026** | High-risk AI requirements apply |
| **August 2027** | Full application |

*Stories about compliance‚Äîor non-compliance‚Äîbecome increasingly relevant as each deadline approaches.*

---

### üîç How to Investigate AI Systems

Investigating algorithmic systems requires a mix of traditional journalism skills and new techniques:

**Freedom of information and access requests**
Public sector AI systems may be subject to transparency and access-to-information laws. In many EU member states you can request:
- Details of AI systems used in government decision-making
- Impact assessments and risk registers for high-risk AI
- Procurement contracts with AI vendors
- Audit logs and accuracy statistics

The EU AI Act itself creates transparency obligations: providers of high-risk AI must maintain documentation, and deployers must log use. These records can be requested.

**Technical approaches**
- **Algorithmic auditing:** Test a system yourself or with affected communities by submitting varied inputs and documenting outputs
- **Source code requests:** Some jurisdictions require public disclosure of algorithms used in public services
- **Crowdsourced data collection:** Coordinate affected individuals to document their experiences (hiring tools, benefits algorithms, content moderation)
- **Public registers:** The EU AI Act will require registration of high-risk AI systems in a public database

**Interviewing affected communities**
The best AI stories are human stories. Find the people affected by a system‚Äîthose denied benefits, screened out in hiring, flagged by fraud detection, or monitored at work. Their experience is both newsworthy and legally relevant (organizations must have evidence that systems aren't discriminating).

**Research resources**
- AlgorithmWatch's AI observatory
- AI Now Institute's annual reports
- The EU AI database (once launched)
- National regulatory databases (DPA enforcement decisions)

---

### üìã Source Guide: Who to Talk To

**Regulators and enforcement bodies**
- National data protection authorities (DPAs) ‚Äî already enforce GDPR and have growing AI mandates
- The European Data Protection Board (EDPB) ‚Äî coordinates national DPAs
- National AI regulatory authorities (as they are established)
- Sector regulators (financial services, healthcare, telecoms)

**Academics and researchers**
- University AI ethics centres (multiple in Germany, Netherlands, UK, France)
- The Alan Turing Institute
- AI policy researchers at think tanks (Bruegel, the Foundation for European Progressive Studies)

**Civil society**
- AlgorithmWatch (algorithmic accountability reporting and research)
- Access Now (digital rights, policy advocacy)
- European Digital Rights (EDRi) (umbrella for 50+ organisations)
- The Ada Lovelace Institute (research on AI and society)
- Amnesty Tech (human rights and technology)

**Affected communities and advocates**
- Workers' organizations (for workplace surveillance stories)
- Disability rights organizations (for accessibility and discrimination angles)
- Migrant support organizations (for AI in border and immigration contexts)
- Consumer organizations

---

We believe in collaborative investigation. If you're working on AI accountability:

### Share Stories
Have you documented cases where AI affected people's lives? We want to hear from you‚Äîyour reporting can inform our resources and help others.

### Suggest Topics
What AI issues deserve more attention? What questions aren't being asked? Your expertise helps shape our coverage.

### Request Information
Looking for background on a specific AI issue? We can point you to relevant resources and experts.

*Contact features coming soon.*

---

## Media Inquiries

If you're a journalist looking for:
- Background information on AI regulation
- Expert sources for commentary
- Data or analysis on AI deployment

*Media contact coming soon.*

---

## Why This Matters

**AI systems are increasingly making decisions that affect millions of people‚Äîoften with little transparency or accountability.** When algorithms determine who gets hired, who gets benefits, who gets surveilled, or who gets opportunities, the public deserves to know how these decisions are made.

Journalists and activists serve as a crucial check on power. You:

- **Investigate** what institutions don't want to reveal
- **Amplify** stories of people affected by AI systems
- **Translate** complex regulations into public understanding
- **Hold** deployers and developers accountable

The EU AI Act creates new transparency requirements and new rights for individuals. But rights only matter if people know they exist‚Äîand if they're enforced.

**Your work makes that possible.**

---

*Start your research with our [EU AI Act Overview](/en/about) or explore the [Rights Framework](/en/rights) to understand what protections exist.*
